{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN Gradient Flow\n",
    "\n",
    "![vanilla_rnn_gradient](resource/lec10/VanillaRnnGradientFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing gradient of $h_0$ involves many factors of W (and Repeated tanh)\n",
    "\n",
    "- W(weight) 가중치 곱은 행렬곱으로 Gradient를 구하는 역전파에서 Transpose 되어야 한다.   \n",
    "  무수히 많은 W를 Transpose -> much time\n",
    "- tanh 연산 -> exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding Gradients\n",
    "- Largest singular value > 1\n",
    "- 매 State에서 같은 가중치를 곱하므로, 가중치에 값이 1 이상이면, exponential하게 Gradient가 커진다.  \n",
    "\n",
    "\n",
    "- 해결: Gradient clipping -> Scale gradient..\n",
    "\n",
    "### Vanishing Gradients\n",
    "- Largest singular value < 1\n",
    "- Exploding과 반대로, 가중치 값이 1 이하면, State수가 많을 때 Gradient가 0으로 수렴한다.  \n",
    "\n",
    "\n",
    "- 이에 대한 해결은, RNN Architecture를 바꾸는 것! -> **LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Short Term Memory)\n",
    "\n",
    "![LSTM Structure](resource/lec10/LSTMStructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point: Sigmoid와의 곱 = 1, 0 으로 on/off 스위치 기능을 하게 된다**  \n",
    "- 각 i, f, o, g Gate는 가중치와 행렬곱이 아닌, Elementwise Multiplication을 한다.  \n",
    "\n",
    "### i , Input Gate\n",
    "- Whether to write to cell\n",
    "- 1: 입력 데이터를 반영한다. / 0: 입력 데이터를 반영하지 않는다. \n",
    "### f, Forget Gate\n",
    "- Whether to erase cell\n",
    "- 1: 과거 데이터를 반영한다. / 0: 과거 데이터를 반영하지 않는다.\n",
    "### o, Output Gate\n",
    "- How much to reveal to cell\n",
    "- 1: 현 스테이트 결과를 다음 스테이트에 내보낸다. / 0: 결과를 다음 스테이트에 내보내지 않는다. \n",
    "### g, Gate Gate\n",
    "- How much to write to cell\n",
    "- tanh로 입력데이터를 정제한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Gradient Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTMGradientFlow](resource/lec10/LSTMGradientFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell Gate 를 통해서 Gradient Flow를 쉬운 연산과 단순한 경로로 Uninterrupted하게 진행시킨다!!**  \n",
    "\n",
    "- Cell Gate에 가중치가 반영되어 있다.\n",
    "- Hidden State는 역전파의 시작 State에서 Tanh 에 한번 적용된다. (= tanh gradient 계산은 한번만 수행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
