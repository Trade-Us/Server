{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network)\n",
    "\n",
    "1. FC - Fully Connected Layer\n",
    "\n",
    "\n",
    "2. Convolution Layer\n",
    "\n",
    "    - Convolving over all spatial location\n",
    "    - Zero Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer (FC layer)\n",
    "\n",
    "![FCLayer](resource/lec5/FCLayer.png)\n",
    "\n",
    "\n",
    "Fully Connected Layer 는 썩 좋은 방법이 아니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer\n",
    "\n",
    "![ConvlutionLayer](resource/lec5/ConvolutionLayer.png)\n",
    "\n",
    "\n",
    "Input image에 convolve filter를 이용하여 input의 이미지에서 특징을 뽑아내는 것이 Convolution Layer 라고 한다. 이때 input은 color 이미지라서 3의 depth를 가지고 filter또한 이와 같은 값인 3을 가져야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex_convolution_layer](resource/lec5/ex_convolution_layer.png)\n",
    "\n",
    "\n",
    "하나의 필터당 하나의 activation map을 얻을 수 있다. 위 의 경우 6개의 5x5필터를 사용하여 6개의 activation map(depth가 6인 activation maps)을 얻었다.\n",
    "\n",
    "![activation_map](resource/lec5/activation_map.png)\n",
    "\n",
    "32개의 5x5필터를 이용해서 activation map을 추출한 모습이다. 하나의 필터당 하나의 activation map이 매치되는 모습을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolving over all spatial location\n",
    "\n",
    "7x7 input with 3x3 filter\n",
    "\n",
    "![convolv_spatial](resource/lec5/convolv_spatial.png)\n",
    "\n",
    "- stride: 1 => 5x5 output\n",
    "\n",
    "\n",
    "- stride: 2 => 3x3 output\n",
    "\n",
    "\n",
    "- stride: 3 => doesn't fit\n",
    "\n",
    "\n",
    "**output size: (N - F) / stride + 1 {N: image size F: filter size}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Padding\n",
    "\n",
    "![zeropadding](resource/lec5/zero_padding.png)\n",
    "\n",
    "\n",
    "Convolving repeatedly with filters (like in pretty deep network) shrinks volumes spatially too fast. It loses out on some of information, using a much smaller number of values in order to represent original image. We would like to maintain full size output. It helps preserve size spatially and apply corner and edge regions  \n",
    "\n",
    "\n",
    "**Common to see CONV layers with stride 1, filter size F, and zero padding with (F-1)/2 -> maintain the same spatial size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
